{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Data Processing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint"
      ],
      "metadata": {
        "id": "fScmtAXjcs3U"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set resolution\n",
        "start_values = np.linspace(10, 2000, 200)\n",
        "start_values = start_values / 20000\n",
        "#start_values"
      ],
      "metadata": {
        "id": "OK25q11l_GsC"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add inputs\n",
        "threshold = start_values\n",
        "#[0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
        "training_file_path = '/content/output.npy'\n",
        "test_file_path = '/content/test_noisy_IR.npy'\n",
        "output_path = '/content/out.csv'"
      ],
      "metadata": {
        "id": "937hXqev5b_m"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read in files and find top thousand frequencies"
      ],
      "metadata": {
        "id": "-fU5bV1RpCF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and normalize\n",
        "training_data_all = np.load(training_file_path)\n",
        "testing_data_all = np.load(test_file_path)\n",
        "\n",
        "for q in range(1, training_data_all.shape[0]):\n",
        "  training_data_all[q] = training_data_all[q] / np.max(training_data_all[q])\n",
        "\n",
        "for r in range(1, testing_data_all.shape[0]):\n",
        "  testing_data_all[r] = testing_data_all[r] / np.max(testing_data_all[r])"
      ],
      "metadata": {
        "id": "0W6j3Ax6hSXB"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that number of columns is equal between training and testing data\n",
        "if training_data_all.shape[1] != testing_data_all.shape[1]:\n",
        "  sys.exit(\"Invalid input\")"
      ],
      "metadata": {
        "id": "agyvTelymfP8"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grand repositories\n",
        "frequency_names = []\n",
        "for fn in range(training_data_all.shape[1]):\n",
        "  temp_name = f'frequency_{fn}'\n",
        "  frequency_names.append(temp_name)\n",
        "frequency_names.append('name')\n",
        "\n",
        "# Build grand training\n",
        "grand_train = pd.DataFrame(columns = frequency_names)\n",
        "divisor = (training_data_all.shape[0] - 1) / 10\n",
        "progress = 1\n",
        "while (progress < (int(training_data_all.shape[0]))):\n",
        "  sorted_indices = np.argsort(training_data_all[progress])\n",
        "  arranged_frequencies = []\n",
        "  for t in range(int(training_data_all.shape[1])):\n",
        "    arranged_frequencies.append(training_data_all[0][sorted_indices[t]])\n",
        "  arranged_frequencies.append((progress - 1) // divisor)\n",
        "  grand_train.loc[progress - 1] = arranged_frequencies\n",
        "  progress = progress + 1\n",
        "\n",
        "# Build grand testing\n",
        "grand_test = pd.DataFrame(columns = frequency_names)\n",
        "divisor = (testing_data_all.shape[0] - 1) / 10\n",
        "progress = 1\n",
        "while (progress < (int(testing_data_all.shape[0]))):\n",
        "  sorted_indices = np.argsort(testing_data_all[progress])\n",
        "  arranged_frequencies = []\n",
        "  for t0 in range(int(testing_data_all.shape[1])):\n",
        "    arranged_frequencies.append(testing_data_all[0][sorted_indices[t0]])\n",
        "  arranged_frequencies.append((progress - 1) // divisor)\n",
        "  grand_test.loc[progress - 1] = arranged_frequencies\n",
        "  progress = progress + 1"
      ],
      "metadata": {
        "id": "poq9XkB6l31g"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Begin random forest tests\n",
        "target_train = grand_train['name']\n",
        "target_test = grand_test['name']\n",
        "output_frame = pd.DataFrame(columns = ['threshold', 'random_forest', 'adv_random_forest'])\n",
        "\n",
        "for s in range(len(threshold)):\n",
        "  output_line = []\n",
        "  output_line.append(threshold[s])\n",
        "  quantity_of_admissible_frequencies = threshold[s] * (training_data_all.shape[1])\n",
        "  admissible_columns = frequency_names[:(int(quantity_of_admissible_frequencies))]\n",
        "\n",
        "  features_train = grand_train[admissible_columns]\n",
        "  features_test = grand_test[admissible_columns]\n",
        "\n",
        "  # Perform first random forest test\n",
        "  rf0 = RandomForestClassifier()\n",
        "  rf0.fit(features_train, target_train)\n",
        "  target_pred0 = rf0.predict(features_test)\n",
        "  accuracy0 = accuracy_score(target_test, target_pred0)\n",
        "  output_line.append(accuracy0)\n",
        "\n",
        "  # Perform enhanced random forest\n",
        "  param_dist = {'n_estimators': randint(50, 500),\n",
        "                'max_depth': randint(1, 20)}\n",
        "  rf1 = RandomForestClassifier()\n",
        "  rand_search = RandomizedSearchCV(rf1,\n",
        "                                  param_distributions = param_dist,\n",
        "                                  n_iter = 5,\n",
        "                                  cv = 5)\n",
        "  rand_search.fit(features_train, target_train)\n",
        "  best_rf = rand_search.best_estimator_\n",
        "  target_pred1 = best_rf.predict(features_test)\n",
        "  accuracy1 = accuracy_score(target_test, target_pred1)\n",
        "  output_line.append(accuracy1)\n",
        "  output_frame.loc[s] = output_line"
      ],
      "metadata": {
        "id": "kpZ2Azk_yuLP"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_frame.to_csv(output_path, index = False)"
      ],
      "metadata": {
        "id": "lXcaG5cKyuDQ"
      },
      "execution_count": 179,
      "outputs": []
    }
  ]
}