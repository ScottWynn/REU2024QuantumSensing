{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.special import jn\n",
    "\n",
    "import jcamp as jc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.1055416 , 2.21108319, 3.31662479, 4.42216639,\n",
       "       5.52770798])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This cell contains my methods for linear interpolation, gaussian smoothing, (vertical) gaussian noise addition, and R/B shift\n",
    "\n",
    "def interpolate_data_to_new_axis(data,originalAxis,newAxis, style = 2):\n",
    "     # this method converts points in data from originalAxis to what their values would be at newAxis by interpoliation,\n",
    "     # style determines how to fill in the points that are beyond the range of originalAxis, 0 fills them in with 0s, 1 fills them in with 1's, 2 filles them in with the last data point\n",
    "     # any other value fills them in by interpolating the last point via the slope from the second to last point\n",
    "    newData = np.zeros(newAxis.size, dtype=type(data[0]))\n",
    "    counter = 0\n",
    "    for i in range(newAxis.size):\n",
    "        if newAxis[i]<originalAxis[0]:\n",
    "            if( style==0):newData[i]=0\n",
    "            elif(style==1):newData[i]=1\n",
    "            elif(style==2):newData[i]=data[0]\n",
    "            else: newData[i]=data[0]+(newAxis[i]-originalAxis[0])*(data[1]-data[0])/(originalAxis[1]-originalAxis[0])\n",
    "        elif newAxis[i]>originalAxis[-1]:\n",
    "            if( style==0):newData[i]=0\n",
    "            elif(style==1):newData[i]=1\n",
    "            elif(style==2):newData[i]=data[-1]\n",
    "            else: newData[i]=data[-1]+(newAxis[i]-originalAxis[-1])*(data[-2]-data[-1])/(originalAxis[-2]-originalAxis[-1])\n",
    "        elif newAxis[i]==originalAxis[counter]:\n",
    "            newData[i] = data[counter]\n",
    "        else:\n",
    "            while originalAxis[counter]<newAxis[i]:\n",
    "                counter+=1\n",
    "            newData[i]=data[counter-1]+(newAxis[i]-originalAxis[counter-1])*(data[counter]-data[counter-1])/(originalAxis[counter]-originalAxis[counter-1])\n",
    "    return(newData)\n",
    "\n",
    "\n",
    "def R_B_shift( axis1, vel,ang): #This method gives a red/blue shifted axis (using wave numbers, and returns it in wave numbers), takes in velocity in m/s and angle in rad\n",
    "    c=3e8\n",
    "    zp1 = (1+vel*np.cos(ang)/c)/np.sqrt(1-vel*vel/(c*c))\n",
    "    axis2=axis1/zp1\n",
    "    return(axis2)\n",
    "\n",
    "def R_B_shift_data(data, axis1, vel,ang):\n",
    "    return(interpolate_data_to_new_axis(data,axis1,R_B_shift(axis1,vel,ang)))\n",
    "\n",
    "\n",
    "def gaussian_smoothing(spectrum, noise_param): #this does gaussian smoothing\n",
    "    #It takes in the spectrum and smooths according to the noise param, which is units of array\n",
    "\n",
    "    shiftFactor=int(spectrum.size/2) #this is  the center of the array\n",
    "\n",
    "    runningVect=np.zeros(spectrum.size) #this will be the output vector\n",
    "\n",
    "    vect = np.array([np.exp(-(j-spectrum.size/2)*(j-spectrum.size/2)/(2*noise_param*noise_param))/np.sqrt(2*np.pi*noise_param*noise_param) for j in range(spectrum.size)])\n",
    "    #^this sets up a gaussian distribution around the center of the array.\n",
    "\n",
    "    for i in range(int(spectrum.size/2)):\n",
    "        runningVect+=np.concatenate((vect[i:],vect[:i]),axis=0)*spectrum[shiftFactor-i]\n",
    "    for i in range(int(spectrum.size/2)):\n",
    "        runningVect+=np.concatenate((vect[-(i+1):],vect[:-(i+1)]),axis=0)*spectrum[shiftFactor+(i)]\n",
    "    return(runningVect)\n",
    "\n",
    "\n",
    "def vertical_noise_addition(spec,noise): #this adds vertical noise to the spectrum the noise is added as a gaussian centred at 0 with \n",
    "    #height given by 'noise', so 'noise' should be in the same units (and relative scale) as spectrum\n",
    "    return(spec+np.random.normal(0,noise,spec.size))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 1 not found\n"
     ]
    }
   ],
   "source": [
    "# This cell contains methods for file conversion, and other helpful conversion stuff\n",
    "# Specifically convert a JCamp object to numpy array, choosing the axis for multiple IR Files\n",
    "# Reaxising the files, importing the files, saving the numpy files,\n",
    "def jc_to_npy(list1):\n",
    "    newlist = np.zeros((2,len(list1['x'])))\n",
    "    newlist[0] = list1['x']\n",
    "    newlist[1] = list1['y']\n",
    "    return newlist\n",
    "\n",
    "\n",
    "def choose_new_axis_multiple_IR(list_of_IR, axislength = 0): #the list of IR should be a list, each entry of which has two rows, the x axis and the y axis\n",
    "    minIR=0 #should be below all the IR spectra values\n",
    "    maxIR=40000 #should be above all IR spectra values\n",
    "    lengthIR=0\n",
    "    for index in range(len(list_of_IR)):\n",
    "        if list_of_IR[index][0][0]>minIR: minIR=list_of_IR[index][0][0]\n",
    "        if list_of_IR[index][0][-1]<maxIR: maxIR=list_of_IR[index][0][-1]\n",
    "        if axislength==0 and len(list_of_IR[index][0])>lengthIR: lengthIR=len(list_of_IR[index][0])\n",
    "\n",
    "    lIR=0\n",
    "    if(not axislength==0): lIR=axislength\n",
    "    else: lIR=2*lengthIR\n",
    "    return(np.linspace(minIR,maxIR,lIR))\n",
    "\n",
    "\n",
    "def reaxis_multiple_IR(list_of_IR, axislength = 0):#the list of IR should be a list, each entry of which has two rows, the x axis and the y axis\n",
    "    #This returns an array with the first entry being the X axis and each subseuent entry being the IR data at that point on the axis.\n",
    "    newX = choose_new_axis_multiple_IR(list_of_IR, axislength)\n",
    "    new_IRs = []\n",
    "    new_IRs.append(newX)\n",
    "    for index in range(len(list_of_IR)):\n",
    "        new_IRs.append(interpolate_data_to_new_axis(list_of_IR[index][1],list_of_IR[index][0],newX, 2))\n",
    "    return(new_IRs)\n",
    "\n",
    "\n",
    "\n",
    "def load_all_jc_data(numberofmolecules = 10): #the files should be called \"_1.jdx\" through \"_numberofmolecules.jdx\" will throw an error if the files dont exist.\n",
    "    # by \"throw an error\" I mean it prints an error and skips that data file, but it will still pass all obtained data\n",
    "    data = []\n",
    "    for i in range(numberofmolecules):\n",
    "        try:\n",
    "            data.append(jc.jcamp_readfile(\"_\"+str(i+1)+\".jdx\"))\n",
    "        except FileNotFoundError:\n",
    "            print(\"file \"+ str(i+1) +\" not found\")\n",
    "            continue\n",
    "\n",
    "    return(data)\n",
    "\n",
    "\n",
    "\n",
    "def convert_all_data(original_data):\n",
    "    new_data=[]\n",
    "    for index in range(len(original_data)):\n",
    "        new_data.append(jc_to_npy(original_data[index]))\n",
    "\n",
    "\n",
    "def load_jc_and_save_converted_IR(n_molec=10):\n",
    "    data=convert_all_data(load_all_jc_data(n_molec))\n",
    "    for index in range(len(data)):\n",
    "        np.save(\"_\"+str(index+1),data[index])\n",
    "\n",
    "        \n",
    "def load_all_npy_data(numberofmolecules = 10): #the files should be called \"_1.npy\" through \"_numberofmolecules.npy\" will throw an error if the files dont exist.\n",
    "    # by \"throw an error\" I mean it prints an error and skips that data file, but it will still pass all obtained data\n",
    "    data = []\n",
    "    for i in range(numberofmolecules):\n",
    "        try:\n",
    "            data.append(np.load(\"_\"+str(i+1)+\".npy\"))\n",
    "        except FileNotFoundError:\n",
    "            print(\"file \"+ str(i+1) +\" not found\")\n",
    "            continue\n",
    "\n",
    "    return(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell runs everything\n",
    "number_of_molecules =10\n",
    "number_of_trials_per_molecule = 100\n",
    "x_axis_resolution = 10000\n",
    "load_method = 0 #0 is from jcamp, 1 is from numpy file\n",
    "#all_at_once = True\n",
    "machine_noise = False\n",
    "\n",
    "noise_ranges=[0.2,x_axis_resolution/100,3e7,0.05] # [0]: original gaussian noise, [1]: smoothing parameter, [2]: max speed parameter, [3]: machine noise parameter\n",
    "\n",
    "'''\n",
    "So This is how the data generation works (no combs in this file)\n",
    "The first step is we load in all the data into the array which has \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "if(load_method==0):\n",
    "    if(machine_noise):\n",
    "        IR_data_1 = reaxis_multiple_IR(convert_all_data(load_all_jc_data(number_of_molecules)),x_axis_resolution)\n",
    "        IR_data_2 = []\n",
    "        IR_data_2.append(IR_data_1[0])\n",
    "        for index in range(len(IR_data_1-1)):\n",
    "            for index2 in range(number_of_trials_per_molecule):\n",
    "                IR_data_2.append( vertical_noise_addition(gaussian_smoothing(vertical_noise_addition(R_B_shift_data(IR_data_1[index+1],IR_data_1[0],np.random.random()*noise_ranges[2],np.random.random()*2*np.pi),np.random.random()*noise_ranges[0]),noise_ranges[1]),np.random.random()*noise_ranges[3]))\n",
    "    if(not machine_noise):\n",
    "        IR_data_1 = reaxis_multiple_IR(convert_all_data(load_all_jc_data(number_of_molecules)),x_axis_resolution)\n",
    "        IR_data_2 = []\n",
    "        IR_data_2.append(IR_data_1[0])\n",
    "        for index in range(len(IR_data_1-1)):\n",
    "            for index2 in range(number_of_trials_per_molecule):\n",
    "                IR_data_2.append( gaussian_smoothing(vertical_noise_addition(R_B_shift_data(IR_data_1[index+1],IR_data_1[0],np.random.random()*noise_ranges[2],np.random.random()*2*np.pi),np.random.random()*noise_ranges[0]),noise_ranges[1]))\n",
    "        \n",
    "if(load_method==2):\n",
    "    if(machine_noise):\n",
    "        IR_data_1 = reaxis_multiple_IR(load_all_npy_data(number_of_molecules),x_axis_resolution)\n",
    "        IR_data_2 = []\n",
    "        IR_data_2.append(IR_data_1[0])\n",
    "        for index in range(len(IR_data_1-1)):\n",
    "            for index2 in range(number_of_trials_per_molecule):\n",
    "                IR_data_2.append( vertical_noise_addition(gaussian_smoothing(vertical_noise_addition(R_B_shift_data(IR_data_1[index+1],IR_data_1[0],np.random.random()*noise_ranges[2],np.random.random()*2*np.pi),np.random.random()*noise_ranges[0]),noise_ranges[1]),np.random.random()*noise_ranges[3]))\n",
    "    if(not machine_noise):\n",
    "        IR_data_1 = reaxis_multiple_IR(convert_all_data(load_all_jc_data(number_of_molecules)),x_axis_resolution)\n",
    "        IR_data_2 = []\n",
    "        IR_data_2.append(IR_data_1[0])\n",
    "        for index in range(len(IR_data_1-1)):\n",
    "            for index2 in range(number_of_trials_per_molecule):\n",
    "                IR_data_2.append( gaussian_smoothing(vertical_noise_addition(R_B_shift_data(IR_data_1[index+1],IR_data_1[0],np.random.random()*noise_ranges[2],np.random.random()*2*np.pi),np.random.random()*noise_ranges[0]),noise_ranges[1]))\n",
    "        \n",
    "\n",
    "# IR_data_2 is the array where the first coordinate is the x-axis data, the \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
