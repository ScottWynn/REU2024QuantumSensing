{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aQPIVyAnWBa"
      },
      "outputs": [],
      "source": [
        "### Import relevant packages\n",
        "\n",
        "# Standard imports\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Imports specific to random forest analysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to determine if an item is a member of a set\n",
        "def inset(element, collection):\n",
        "  flag = 0\n",
        "  for elt in collection:\n",
        "    if element == elt:\n",
        "      flag = flag + 1\n",
        "      break\n",
        "  if flag == 0:\n",
        "    return False\n",
        "  else:\n",
        "    return True"
      ],
      "metadata": {
        "id": "BTJgY2JddRV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Assemble a data frame with all IR data\n",
        "\n",
        "# Molecule to number key\n",
        "# C2H2   0\n",
        "# CH4    1\n",
        "# NH3    2\n",
        "\n",
        "# Load in and label IR data\n",
        "c2h2_unprocessed = np.load('/content/C2H2_Data_6_27.npy')\n",
        "c2h2_normalized = np.abs(c2h2_unprocessed)\n",
        "c2h2_names = np.full(shape = c2h2_normalized.shape[0], fill_value = 0)\n",
        "c2h2_names = c2h2_names.reshape((c2h2_normalized.shape[0], 1))\n",
        "c2h2_verified = np.concatenate((c2h2_normalized, c2h2_names), axis = 1)\n",
        "\n",
        "ch4_unprocessed = np.load('/content/CH4_Data_6_27.npy')\n",
        "ch4_normalized = np.abs(ch4_unprocessed)\n",
        "ch4_names = np.full(shape = ch4_normalized.shape[0], fill_value = 1)\n",
        "ch4_names = ch4_names.reshape((ch4_normalized.shape[0], 1))\n",
        "ch4_verified = np.concatenate((ch4_normalized, ch4_names), axis = 1)\n",
        "\n",
        "nh3_unprocessed = np.load('/content/NH3_Data_6_27.npy')\n",
        "nh3_normalized = np.abs(nh3_unprocessed)\n",
        "nh3_names = np.full(shape = nh3_normalized.shape[0], fill_value = 2)\n",
        "nh3_names = nh3_names.reshape((nh3_normalized.shape[0], 1))\n",
        "nh3_verified = np.concatenate((nh3_normalized, nh3_names), axis = 1)\n",
        "\n",
        "# Prepare Pandas dataframe\n",
        "column_names = []\n",
        "column_names_wo_name = []\n",
        "for i in range(20000):\n",
        "  title = f'channel_{i}'\n",
        "  column_names.append(title)\n",
        "  column_names_wo_name.append(title)\n",
        "column_names.append('molecule')\n",
        "\n",
        "full_data = pd.DataFrame(columns = column_names)\n",
        "\n",
        "progress = 0\n",
        "while (progress < 100):\n",
        "  full_data.loc[progress] = c2h2_verified[progress]\n",
        "  progress = progress + 1\n",
        "\n",
        "while (progress < 201):\n",
        "  full_data.loc[progress] = ch4_verified[progress - 100]\n",
        "  progress = progress + 1\n",
        "\n",
        "while (progress < 300):\n",
        "  full_data.loc[progress] = nh3_verified[progress - 201]\n",
        "  progress = progress + 1"
      ],
      "metadata": {
        "id": "g3Ff77lln7go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine key parameters\n",
        "channel_quantity = [3]\n",
        "training_data_size_per_molecule = [3]   #, 5, 7, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]\n",
        "channel_samples = 1     # Each sample contains channel_quantity channels, but different channels in different samples\n",
        "row_samples = 1         # Each sample contains training_data_size_per_molecule rows, but different rows in different samples\n",
        "\n",
        "output = pd.DataFrame(columns = ['channel_quantity', 'channel_sample', 'channels_used', 'training_size', 'row_sample', 'rows_used', 'accuracy'])\n",
        "progress = 0\n",
        "\n",
        "for cq in channel_quantity:\n",
        "  for t in range(channel_samples):\n",
        "    # For each iteration of the loop, select the cq channels that will be examined\n",
        "    sample_key = np.sort(random.sample(range(c2h2_normalized.shape[1]), cq))\n",
        "    channel_names_w_label = []\n",
        "    channel_names_wo_label = []\n",
        "    for k in sample_key:\n",
        "      channel_name = f'channel_{k}'\n",
        "      channel_names_w_label.append(channel_name)\n",
        "      channel_names_wo_label.append(channel_name)\n",
        "    channel_names_w_label.append('molecule')\n",
        "    selected_channels = full_data[channel_names_w_label]\n",
        "\n",
        "    for td in training_data_size_per_molecule:\n",
        "      for u in range(row_samples):\n",
        "        # For each iteration of the loop, select the td rows that will be examined for each molecule\n",
        "        c2h2_samples = np.sort(random.sample(range(100), td))\n",
        "        ch4_samples = np.sort(random.sample(range(100, 201), td))\n",
        "        nh3_samples = np.sort(random.sample(range(201, 300), td))\n",
        "\n",
        "        selected_rows = pd.DataFrame(columns = channel_names_w_label)\n",
        "        deselected_rows = pd.DataFrame(columns = channel_names_w_label)\n",
        "\n",
        "        row_building_selected_rows = 0\n",
        "        row_building_deselected_rows = 0\n",
        "        grand_advancement = 0\n",
        "\n",
        "        # Build the data frames with the selected rows and the deselected rows\n",
        "        while (grand_advancement < 100):\n",
        "          if inset(grand_advancement, c2h2_samples):\n",
        "            selected_rows.loc[row_building_selected_rows] = selected_channels.loc[grand_advancement]\n",
        "            row_building_selected_rows = row_building_selected_rows + 1\n",
        "          else:\n",
        "            deselected_rows.loc[row_building_deselected_rows] = selected_channels.loc[grand_advancement]\n",
        "            row_building_deselected_rows = row_building_deselected_rows + 1\n",
        "          grand_advancement = grand_advancement + 1\n",
        "\n",
        "        while (grand_advancement < 201):\n",
        "          if inset(grand_advancement, ch4_samples):\n",
        "            selected_rows.loc[row_building_selected_rows] = selected_channels.loc[grand_advancement]\n",
        "            row_building_selected_rows = row_building_selected_rows + 1\n",
        "          else:\n",
        "            deselected_rows.loc[row_building_deselected_rows] = selected_channels.loc[grand_advancement]\n",
        "            row_building_deselected_rows = row_building_deselected_rows + 1\n",
        "          grand_advancement = grand_advancement + 1\n",
        "\n",
        "        while (grand_advancement < 300):\n",
        "          if inset(grand_advancement, nh3_samples):\n",
        "            selected_rows.loc[row_building_selected_rows] = selected_channels.loc[grand_advancement]\n",
        "            row_building_selected_rows = row_building_selected_rows + 1\n",
        "          else:\n",
        "            deselected_rows.loc[row_building_deselected_rows] = selected_channels.loc[grand_advancement]\n",
        "            row_building_deselected_rows = row_building_deselected_rows + 1\n",
        "          grand_advancement = grand_advancement + 1\n",
        "\n",
        "        # Split into feature and target columns\n",
        "        feature_train = selected_rows.drop('molecule', axis = 1)\n",
        "        target_train = selected_rows['molecule']\n",
        "\n",
        "        feature_test = deselected_rows.drop('molecule', axis = 1)\n",
        "        target_test = deselected_rows['molecule']\n",
        "\n",
        "        # Use the random forest to make predictions\n",
        "        rf = RandomForestClassifier()\n",
        "        rf.fit(feature_train, target_train)\n",
        "        predictions = rf.predict(feature_test)\n",
        "        accuracy = accuracy_score(target_test, predictions)\n",
        "\n",
        "        # Write results to an ouput file\n",
        "        output_line = []\n",
        "        output_line.append(cq)\n",
        "        output_line.append(t)\n",
        "        output_line.append(sample_key)\n",
        "        output_line.append(td)\n",
        "        output_line.append(u)\n",
        "\n",
        "        row_collection = []\n",
        "        row_collection.append(c2h2_samples)\n",
        "        row_collection.append(ch4_samples)\n",
        "        row_collection.append(nh3_samples)\n",
        "        output_line.append(row_collection)\n",
        "\n",
        "        output_line.append(accuracy)\n",
        "        output.loc[progress] = output_line\n",
        "        progress = progress + 1"
      ],
      "metadata": {
        "id": "s-l5TSIYnY4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write output to a downloadable file\n",
        "output.to_csv('/content/output.csv', index = False)"
      ],
      "metadata": {
        "id": "GZq2_Mx7pyhn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}